{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"18IbkHUWNlpH7XYdiGBtZpALUO-u25T3a","authorship_tag":"ABX9TyNMq+7jf3cebIPY+3+dfhyi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"719be045f84c40a39b1b384df772b03e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88b50c5890c94c3fb8bf73608521bdab","IPY_MODEL_4720ff33415a4de3a870fc749af71d72","IPY_MODEL_e186b766a2024a688391c227756edc7e"],"layout":"IPY_MODEL_7663f75d249940d090a2d56bb4f5f8ef"}},"88b50c5890c94c3fb8bf73608521bdab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24977143402f46b8bf17923b6e0fa0d3","placeholder":"â€‹","style":"IPY_MODEL_d8ac69bb2cf14c0fb10a1f96430a0ce3","value":"100%"}},"4720ff33415a4de3a870fc749af71d72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8731e69b60ad4068b99108d2dae3cbf6","max":111898327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e546c04458d4312b97c443305f226ec","value":111898327}},"e186b766a2024a688391c227756edc7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fee3e09a97442c08ab1fc09bfb2672f","placeholder":"â€‹","style":"IPY_MODEL_e95d2690db724c69a6336eed7aeb83be","value":"â€‡107M/107Mâ€‡[00:00&lt;00:00,â€‡348MB/s]"}},"7663f75d249940d090a2d56bb4f5f8ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24977143402f46b8bf17923b6e0fa0d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8ac69bb2cf14c0fb10a1f96430a0ce3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8731e69b60ad4068b99108d2dae3cbf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e546c04458d4312b97c443305f226ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3fee3e09a97442c08ab1fc09bfb2672f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e95d2690db724c69a6336eed7aeb83be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install -U \"torch>=2.4.0\" \"torchvision>=0.19.0\" facenet-pytorch \"numpy>=2.0,<2.3\" \"opencv-python-headless==4.12.0.88\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"f3uV9BvMim0E","executionInfo":{"status":"ok","timestamp":1761722604888,"user_tz":-330,"elapsed":218139,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"7c7dd4d1-25b1-4361-bd2c-e6b1a20685d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Collecting torch>=2.4.0\n","  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n","Requirement already satisfied: torchvision>=0.19.0 in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Collecting torchvision>=0.19.0\n","  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n","Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: numpy<2.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Collecting numpy<2.3,>=2.0\n","  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python-headless==4.12.0.88 in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.13.3)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (9.10.2.21)\n","Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.4.0)\n","  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0)\n","  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0)\n","  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0)\n","  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.4.0)\n","  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (0.7.1)\n","Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0)\n","  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n","Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0)\n","  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n","Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0)\n","  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.4.0)\n","  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0)\n","  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.5.0 (from torch>=2.4.0)\n","  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.19.0) (11.3.0)\n","INFO: pip is looking at multiple versions of facenet-pytorch to determine which version is compatible with other requirements. This could take a while.\n","Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (2.32.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch) (2025.10.5)\n","Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, torchvision, facenet-pytorch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.4.0\n","    Uninstalling triton-3.4.0:\n","      Successfully uninstalled triton-3.4.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nvshmem-cu12\n","    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n","    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n","      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n","    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.3\n","    Uninstalling nvidia-nccl-cu12-2.27.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufile-cu12\n","    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n","    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n","      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.8.0+cu126\n","    Uninstalling torch-2.8.0+cu126:\n","      Successfully uninstalled torch-2.8.0+cu126\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.23.0+cu126\n","    Uninstalling torchvision-0.23.0+cu126:\n","      Successfully uninstalled torchvision-0.23.0+cu126\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.0 which is incompatible.\n","fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\n","tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed facenet-pytorch-2.5.3 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 torch-2.9.0 torchvision-0.24.0 triton-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","torch","torchgen"]},"id":"9df1af7c441c492e83a79759daad9c6d"}},"metadata":{}}]},{"cell_type":"code","source":["import os, pickle\n","import torch\n","import numpy as np\n","from PIL import Image\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","from sklearn.metrics.pairwise import cosine_similarity\n","import cv2"],"metadata":{"id":"0siVovKPgzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RAW_DIR = \"/content/drive/MyDrive/My_Machine_Learning/face_recognition-pending/dataset/faces01\"\n","PROC_DIR = \"/content/drive/MyDrive/My_Machine_Learning/face_recognition-pending/dataset/processed_face_images\"\n","EMB_FILE = \"/content/drive/MyDrive/My_Machine_Learning/face_recognition-pending/dataset/face_embeddings.pkl\"\n","ALLOWED = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"âœ… PyTorch device:\", device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22WxpSLdX4ry","executionInfo":{"status":"ok","timestamp":1761722744259,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"a94442b4-357f-4831-fb2a-8e6fe931f1f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… PyTorch device: cuda:0\n"]}]},{"cell_type":"code","source":["mtcnn  = MTCNN(image_size=160, margin=20, device=device, post_process=True)\n","resnet = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)"],"metadata":{"id":"G11ToQ9ThX-T","executionInfo":{"status":"ok","timestamp":1761722750828,"user_tz":-330,"elapsed":1420,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["719be045f84c40a39b1b384df772b03e","88b50c5890c94c3fb8bf73608521bdab","4720ff33415a4de3a870fc749af71d72","e186b766a2024a688391c227756edc7e","7663f75d249940d090a2d56bb4f5f8ef","24977143402f46b8bf17923b6e0fa0d3","d8ac69bb2cf14c0fb10a1f96430a0ce3","8731e69b60ad4068b99108d2dae3cbf6","2e546c04458d4312b97c443305f226ec","3fee3e09a97442c08ab1fc09bfb2672f","e95d2690db724c69a6336eed7aeb83be"]},"outputId":"53404b89-544c-40e2-ae83-8e0cc9f9234f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/107M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"719be045f84c40a39b1b384df772b03e"}},"metadata":{}}]},{"cell_type":"code","source":["print(\"torch:\", torch.__version__)\n","print(\"torchvision:\", __import__('torchvision').__version__)\n","print(\"numpy:\", np.__version__)\n","print(\"opencv:\", cv2.__version__)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","!nvidia-smi | head -n 20"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqFSBKAkjUQ9","executionInfo":{"status":"ok","timestamp":1761722814800,"user_tz":-330,"elapsed":93,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"649e6f3d-ad69-4ce0-9b25-7d02b7f494f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch: 2.9.0+cu128\n","torchvision: 0.24.0+cu128\n","numpy: 2.2.6\n","opencv: 4.12.0\n","CUDA available: True\n","Wed Oct 29 07:26:55 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P0             28W /   70W |     224MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# run this cell only if you wanna check the folder is empty or not\n","\"\"\"\n","print(\"PROC_DIR exists:\", os.path.exists(PROC_DIR))\n","if os.path.exists(PROC_DIR):\n","    people = os.listdir(PROC_DIR)\n","    print(\"Folders inside PROC_DIR:\", people)\n","    for p in people:\n","        pdir = os.path.join(PROC_DIR, p)\n","        print(p, \"->\", len(os.listdir(pdir)) if os.path.isdir(pdir) else \"not a folder\")\n","\n","\"\"\""],"metadata":{"id":"iawpqsDyqwNy","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1759859123986,"user_tz":-330,"elapsed":22,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"c2d342a8-72ca-461e-cfe5-9c999019ab0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nprint(\"PROC_DIR exists:\", os.path.exists(PROC_DIR))\\nif os.path.exists(PROC_DIR):\\n    people = os.listdir(PROC_DIR)\\n    print(\"Folders inside PROC_DIR:\", people)\\n    for p in people:\\n        pdir = os.path.join(PROC_DIR, p)\\n        print(p, \"->\", len(os.listdir(pdir)) if os.path.isdir(pdir) else \"not a folder\")\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#!rm -rf \"/content/drive/MyDrive/My_Machine_Learning/face_recognition-pending/dataset/face_embeddings.pkl\"\n","# remove old en=mbedding if requires\n","if os.path.exists(EMB_FILE):\n","    os.remove(EMB_FILE)\n","    print(\"removed old embeddings file.\")\n"],"metadata":{"id":"ppm_tsuxlGT5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761722831012,"user_tz":-330,"elapsed":1354,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"df5fca62-cf49-465e-c264-58ca4aa1c8e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed old embeddings file.\n"]}]},{"cell_type":"code","source":["def iter_images(folder):\n","    \"\"\"Yield (person_name, person_dir, image_files)\"\"\"\n","    for person in sorted(os.listdir(folder)):\n","        pdir = os.path.join(folder, person)\n","        if not os.path.isdir(pdir):\n","            continue\n","        files = [f for f in sorted(os.listdir(pdir))\n","                 if not f.startswith(\".\") and os.path.splitext(f)[1].lower() in ALLOWED]\n","        if files:\n","            yield person, pdir, files\n"],"metadata":{"id":"bcCbXV9go6bs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Process each person folder\n","\"\"\"\n","for person in sorted(os.listdir(RAW_DIR)):\n","    pdir = os.path.join(RAW_DIR, person)\n","    if not os.path.isdir(pdir):\n","        continue\n","\n","    out_dir = os.path.join(PROC_DIR, person)\n","    os.makedirs(out_dir, exist_ok=True)\n","\n","    print(f\"ğŸ§ Detecting faces for: {person}\")\n","    for img_name in os.listdir(pdir):\n","        img_path = os.path.join(pdir, img_name)\n","        out_path = os.path.join(out_dir, img_name)\n","        try:\n","            img = Image.open(img_path).convert(\"RGB\")\n","            face = mtcnn(img, save_path=out_path)\n","            if face is None:\n","                print(f\"âš ï¸ No face found in {img_name}\")\n","        except Exception as e:\n","            print(f\"âŒ Error on {img_name}: {e}\")\n","\n","  \"\"\""],"metadata":{"id":"hfMVUkcjrRUr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# only run this cell to check how many images are there in each folder /\n","\"\"\"\n","print(\"Folders in PROC_DIR:\", os.listdir(PROC_DIR))\n","for person in os.listdir(PROC_DIR):\n","    pdir = os.path.join(PROC_DIR, person)\n","    print(person, \"â†’\", len(os.listdir(pdir)), \"images\")\n","\"\"\""],"metadata":{"id":"-DZVI7LorYes"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings, names = [], []\n","BATCH = 64\n","\n","with torch.no_grad():\n","    for person, pdir, files in iter_images(PROC_DIR):\n","        print(f\"Processing: {person} ({len(files)} images)\")\n","        batch = []\n","        for fn in files:\n","            try:\n","                img = Image.open(os.path.join(pdir, fn)).convert(\"RGB\")\n","                t = torch.from_numpy(np.asarray(img)).float().permute(2, 0, 1) / 255.0\n","                batch.append(t)\n","                if len(batch) == BATCH:\n","                    x = torch.stack(batch).to(device)\n","                    em = resnet(x).cpu().numpy()\n","                    em = em / np.linalg.norm(em, axis=1, keepdims=True)\n","                    embeddings.append(em)\n","                    names.extend([person] * len(batch))\n","                    batch = []\n","            except Exception as e:\n","                print(\"Skipped:\", fn, \"Reason:\", e)\n","\n","        # leftover images\n","        if batch:\n","            x = torch.stack(batch).to(device)\n","            em = resnet(x).cpu().numpy()\n","            em = em / np.linalg.norm(em, axis=1, keepdims=True)\n","            embeddings.append(em)\n","            names.extend([person] * len(batch))\n","\n","# Combine and save\n","emb_array = np.vstack(embeddings).astype(np.float32) if embeddings else np.zeros((0,512), np.float32)\n","\n","with open(EMB_FILE, \"wb\") as f:\n","    pickle.dump({\n","        \"embeddings\": emb_array,\n","        \"names\": names,\n","        \"model\": \"InceptionResnetV1-vggface2\",\n","        \"normalized\": True\n","    }, f)\n","\n","print(f\"Saved embeddings to: {EMB_FILE}\")\n","print(f\"Shape: {emb_array.shape}, Total names: {len(names)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyN1S0Bkhcub","executionInfo":{"status":"ok","timestamp":1761722861333,"user_tz":-330,"elapsed":12673,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"e3181f95-12e9-4e24-974b-6640b246d8ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: Ashutosh (4 images)\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2582928134.py:11: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n","  t = torch.from_numpy(np.asarray(img)).float().permute(2, 0, 1) / 255.0\n"]},{"output_type":"stream","name":"stdout","text":["Processing: Chachu (4 images)\n","Processing: Mom (3 images)\n","Processing: Muskaa (4 images)\n","Processing: Naitik (5 images)\n","Processing: Papa (3 images)\n","Processing: Vishal (5 images)\n","Saved embeddings to: /content/drive/MyDrive/My_Machine_Learning/face_recognition-pending/dataset/face_embeddings.pkl\n","Shape: (28, 512), Total names: 28\n"]}]},{"cell_type":"code","source":["with open(EMB_FILE, \"rb\") as f:\n","    data = pickle.load(f)\n","\n","stored_embeddings = np.array(data[\"embeddings\"])\n","stored_names = np.array(data[\"names\"])\n","\n","print(\"Embeddings and names loaded successfully!\")\n","print(\"Total embeddings:\", len(stored_embeddings))\n","for i in range(min(5, len(stored_names))):\n","    print(f\"{i+1}. {stored_names[i]}  â†’  norm: {np.linalg.norm(stored_embeddings[i]):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQSGcKkflGEf","executionInfo":{"status":"ok","timestamp":1759859209741,"user_tz":-330,"elapsed":31,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"e6cdde8a-074e-4f86-91af-dfacdd17cc83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Embeddings and names loaded successfully!\n","Total embeddings: 28\n","1. Ashutosh  â†’  norm: 1.0000\n","2. Ashutosh  â†’  norm: 1.0000\n","3. Ashutosh  â†’  norm: 1.0000\n","4. Ashutosh  â†’  norm: 1.0000\n","5. Chachu  â†’  norm: 1.0000\n"]}]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","from facenet_pytorch import InceptionResnetV1, MTCNN\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","mtcnn = MTCNN(image_size=160, margin=20, device=device, post_process=True)\n","resnet = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)\n","\n","def get_face_embedding(image_path):\n","    \"\"\"Extract a 512-dim embedding from an image.\"\"\"\n","    img = Image.open(image_path).convert(\"RGB\")\n","    face = mtcnn(img)\n","    if face is None:\n","        print(\"No face detected.\")\n","        return None\n","    with torch.no_grad():\n","        embeddings = resnet(face.unsqueeze(0).to(device)).cpu().numpy()[0]\n","        embeddings = embeddings / np.linalg.norm(embeddings)\n","    return embeddings"],"metadata":{"id":"Q-Nr52XkoREb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stored_embeddings = embeddings\n","stored_names = names\n","\n","\n","# ====== Main Recognition Function ======\n","def recognize_face(image_path, threshold=0.6):\n","    \"\"\"\n","    Compare input image against stored embeddings.\n","    Returns (best_match_name, similarity_score).\n","    \"\"\"\n","    emb = get_face_embedding(image_path)\n","    if emb is None:\n","        return None, 0.0\n","\n","    # Compute cosine similarity between this and all stored embeddings\n","    sims = cosine_similarity([emb], stored_embeddings)[0]\n","    best_idx = np.argmax(sims)\n","    best_score = sims[best_idx]\n","    best_name = stored_names[best_idx]\n","\n","    if best_score >= threshold:\n","        print(f\"Match: {best_name} (confidence {best_score:.3f})\")\n","        return best_name, best_score\n","    else:\n","        print(f\"Unknown face (max similarity {best_score:.3f})\")\n","        return \"Unknown\", best_score\n"],"metadata":{"id":"0uc_1y9AoJjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","MODEL_PATH = \"inception_resnet_v1_vggface2.pth\"\n","torch.save(resnet.state_dict(), MODEL_PATH)\n","print(\"âœ… Model saved at:\", MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MptL2Jm1rHlt","executionInfo":{"status":"ok","timestamp":1759656717006,"user_tz":-330,"elapsed":255,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"eb2ae49a-4058-4773-b404-fc6218e93ab8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Model saved at: inception_resnet_v1_vggface2.pth\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"inception_resnet_v1_vggface2.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"qtK699GStqhg","executionInfo":{"status":"ok","timestamp":1759657137095,"user_tz":-330,"elapsed":15,"user":{"displayName":"Vishal Sharma","userId":"18064758065265427724"}},"outputId":"73048f7f-5ba1-4053-8758-de331ca03508"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1454e893-677a-4d6f-8362-e24effe3fcfb\", \"inception_resnet_v1_vggface2.pth\", 112028385)"]},"metadata":{}}]}]}